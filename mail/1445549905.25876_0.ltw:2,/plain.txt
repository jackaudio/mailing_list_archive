Date:        Thu, 22 Oct 2015 17:38:18 -0400
From:        Paul Davis  <[hidden] at linuxaudiosystems dot com>
To:          Caleb Crome <[hidden] at crome dot org>
Cc:          JACK <[hidden] at lists dot jackaudio dot org>
In-Reply-To: Caleb Crome [Jack-Devel] Is it possible/reasonable to change jack to an int data type? (1445549022.25174_0.ltw:2,)
Follow-Up:   Caleb Crome Re: [Jack-Devel] Is it possible/reasonable to change jack to an int data type? (1445550110.26044_0.ltw:2,)

Subject:     Re: [Jack-Devel] Is it possible/reasonable to change jack to an int data type?

On Thu, Oct 22, 2015 at 5:23 PM, Caleb Crome <[hidden]> wrote:

> Hi,
>   I'm building a test application for doing bit-perfect loopback
> testing on my sound card drivers.  However, since jack uses floating
> point types, it seems that I can't get a bit-perfect data in and out
> from (16-bit) 0x0000 to 0xFFFF.  the LSB seems to get rounded on and
> off, and also it seems that jack enforces a range of  -32767 to +32767
> instead of -32768 to +32767 (for 16-bit audio).
>
> Is it possible that it's as simple as changing jack_default_audio_sample_t?
>

nope.

far easier to just write your own ALSA test client.

i wouldn't get too deeply into this issue unless you've already read bjorn:

http://blog.bjornroche.com/2009/12/int-float-int-its-jungle-out-there.html
http://blog.bjornroche.com/2009/12/linearity-and-dynamic-range-in-int.html

this email thread has some good stuff too:

http://lists.apple.com/archives/coreaudio-api/2009/Dec/msg00046.html

but perhaps you've already done that :)

1445549905.25876_0.ltw:2, <CAFa_cKkAhe6AcRsqXq9twvCeFagG94FV5Qr78EmZiO=8+Bqxnw at mail dot gmail dot com>
________________________________________________________________________________

